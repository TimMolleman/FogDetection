{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsample\n",
    "import psycopg2\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchsample import transforms as ts_transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from mlxtend.evaluate import confusion_matrix\n",
    "# from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Classes for Testing Meteo Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class meteo_NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(meteo_NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class resnet18_meteo(nn.Module):\n",
    "    def __init__(self, resnet18, meteo_NN, num_classes):\n",
    "        super(resnet18_meteo, self).__init__()\n",
    "        \n",
    "        # Respectively a torchvision resnet-18 and a 1-hidden layer NN\n",
    "        self.resnet_CNN = resnet18\n",
    "        self.meteo_net = meteo_NN\n",
    "        \n",
    "        # Sizes of the FC layers of both NN's\n",
    "        self.len_fc_resnet = self.resnet_CNN.fc.in_features\n",
    "        self.len_fc_meteo = self.meteo_net.fc2.out_features\n",
    "        \n",
    "        # Extract convolutional block out of predefined network\n",
    "        self.modules=list(self.resnet_CNN.children())[:-1]\n",
    "        self.resnet18_convblocks= nn.Sequential(*self.modules)\n",
    "        \n",
    "        self.fc = nn.Linear(self.len_fc_resnet + self.len_fc_meteo, num_classes)\n",
    "\n",
    "    def forward(self, img_x, meteo_x):\n",
    "        \n",
    "        # Both should be flattened layers at end of networks\n",
    "        img_x = self.resnet18_convblocks(img_x)\n",
    "        meteo_x = self.meteo_net(meteo_x)\n",
    "\n",
    "        # Flatten convolutional features\n",
    "        img_x_flattened = img_x.view(img_x.size(0), -1)\n",
    "\n",
    "        # Concat the outputs of CNN and meteo-NN in fully connected layer\n",
    "        out = torch.cat([img_x_flattened, meteo_x], dim=1)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simple_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,              # input height\n",
    "                out_channels=32,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(32, 32, 3, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(32, 32, 3, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, 3, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )     \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.out = nn.Linear(576, 3)   # fully connected layer, output 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = self.dropout(x) \n",
    "        output = self.out(x)\n",
    "        return output   # return x for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Certain/uncertain plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Uncertain Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_uncertain(outputs, corrects, predictions, loss, a, k=15):\n",
    "    loss_differences = []\n",
    "\n",
    "    for i, output in enumerate(outputs):\n",
    "        if corrects[i] == a:\n",
    "            values, top2_idx = torch.topk(output, 2)\n",
    "            top2 = output[top2_idx]\n",
    "            difference = top2[0] - top2[1]\n",
    "            loss_differences.append(difference.data[0])\n",
    "        else:\n",
    "            loss_differences.append(1000)\n",
    "\n",
    "    loss_differences = np.asarray(loss_differences)\n",
    "    indices = np.argsort(loss_differences)[:k]\n",
    "\n",
    "    for idx in indices:\n",
    "        print(test_filepaths[idx])\n",
    "        plt.imshow(test_features[idx])\n",
    "        plt.title('target: {} prediction: {} loss: {:.2f}'.format(test_targets[idx], predictions[idx], loss.data[idx]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CM Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Confusion matrix helper\n",
    "def show_cm(targets, predictions):\n",
    "    cm = confusion_matrix(y_target=targets, \n",
    "                      y_predicted=predictions, \n",
    "                      binary=False)\n",
    "\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    classes = ['no fog', 'light fog', 'dense fog']\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def show_cm(targets, predictions):\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(targets, predictions)\n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, title='Confusion matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNMIDataset(Dataset):\n",
    "    def __init__(self, images, targets, filepaths, meteo=None, transforms=None):\n",
    "    \n",
    "        self.transforms = transforms\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.filepaths = filepaths\n",
    "        self.meteo = meteo\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        target = self.targets[index]\n",
    "        filepath = self.filepaths[index]\n",
    "        \n",
    "        if self.transforms != None:\n",
    "            image = self.transforms(image)\n",
    "        if len(self.meteo) > 0:\n",
    "            meteo = self.meteo[index]\n",
    "            return (image, target, index, filepath, meteo)\n",
    "        else:\n",
    "            return (image, target, index, filepath)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomCrop(80),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.CenterCrop(80),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_average_accuracy(predictions, targets):\n",
    "  \n",
    "    # Lists for holding corrects\n",
    "    no_fog_correct = 0\n",
    "    light_fog_correct = 0\n",
    "    dense_fog_correct = 0\n",
    "\n",
    "    for pred, target in zip(predictions, targets):\n",
    "        if pred == 0 and target == 0:\n",
    "            no_fog_correct += 1\n",
    "        elif pred == 1 and target == 1:\n",
    "            light_fog_correct += 1\n",
    "        elif pred == 2 and target == 2:\n",
    "            dense_fog_correct += 1\n",
    "\n",
    "    # Validation counts\n",
    "    total = np.bincount(test_targets)\n",
    "    no_fog_total = total[0]\n",
    "    light_fog_total = total[1]\n",
    "    dense_fog_total = total[2]\n",
    "\n",
    "    # Accuracy per class\n",
    "    acc_no_fog = no_fog_correct / no_fog_total\n",
    "    acc_light = light_fog_correct / light_fog_total\n",
    "    acc_dense = dense_fog_correct / dense_fog_total\n",
    "\n",
    "    average_acc = (acc_no_fog + acc_light + acc_dense) / 3 * 100\n",
    "\n",
    "    return average_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Curve Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_curves(training_loss, validation_loss):\n",
    "    \"\"\"\n",
    "    Plots loss curves after model training.\n",
    "    \n",
    "    :param training_loss: List with training loss for every epoch.\n",
    "    :param validation_loss: List with validation loss for every epoch.\n",
    "    \"\"\"\n",
    "    train_plot, = plt.plot(training_loss, label='Training')\n",
    "    val_plot, = plt.plot(validation_loss, label='Validation')\n",
    "    plt.title('Loss curves (training/validation)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(handles=[train_plot, val_plot])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Arrays (Non-Meteo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/NoMeteo/test_images.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-46fb726c5311>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/NoMeteo/test_images.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/NoMeteo/test_targets.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_filepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/NoMeteo/test_filepaths.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science_36/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/NoMeteo/test_images.npy'"
     ]
    }
   ],
   "source": [
    "test_features = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/NoMeteo/test_images.npy')\n",
    "test_targets = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/NoMeteo/test_targets.npy')\n",
    "test_filepaths = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/NoMeteo/test_filepaths.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Arrays (IDW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/MeteoValTestInterpolation(ver2)/test_images_meteo_IDW.npy')\n",
    "test_targets = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/MeteoValTestInterpolation(ver2)/test_targets_meteo_IDW.npy')\n",
    "test_filepaths = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/MeteoValTestInterpolation(ver2)/test_filepaths_meteo_IDW.npy')\n",
    "test_meteo = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/MeteoValTestInterpolation(ver2)/test_meteo_meteo_IDW.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Arrays (harmonie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/harmonie/test_images_harmonie.npy')\n",
    "test_targets = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/harmonie/test_targets_harmonie.npy')\n",
    "test_filepaths = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/harmonie/test_filepaths_harmonie.npy')\n",
    "test_meteo = np.load('/Volumes/TIMPP/UnusedKNMI/numpyfiles/test_refined/harmonie/test_meteo_harmonie.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function That Loads Models to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(filepath):\n",
    "    '''\n",
    "    Loads a trained model.\n",
    "    \n",
    "    :param filepath: Path to the trained model.\n",
    "    '''\n",
    "    loaded_model = torch.load(filepath, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    \n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = KNMIDataset(test_features, test_targets, test_filepaths, test_meteo,transforms=data_transforms['validation'])\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=len(test_features),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best overall accuracy: 98.78%.\n",
      "Best average accuracy: 90.98%. At epoch 10\n",
      "Best f1-macro: 0.751. At epoch 38\n",
      "Confusion Matrix best f1-macro validation:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b9c4438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAINED_MODELS_DIR = '/Volumes/TIMPP/TrainedModels'\n",
    "\n",
    "# Experiment 1\n",
    "# checkpoint = load_model(TRAINED_MODELS_DIR + '/Experiment1/new_images/highway/tune2new/completed_tuner2.pth.tar')\n",
    "# checkpoint = load_model(TRAINED_MODELS_DIR + '/Experiment1/new_images/highway+knmi2/tune4(2)/completed_tuner4.pth.tar')\n",
    "# checkpoint = load_model(TRAINED_MODELS_DIR + '/Experiment1/new_images/knmi/tune4/completed_tuner4.pth.tar')\n",
    "# checkpoint = load_model(TRAINED_MODELS_DIR + '/Experiment1/new_images/highway(noChange)/classifier/completed_classifier.pth.tar')\n",
    "\n",
    "# Experiment 2\n",
    "checkpoint = load_model(TRAINED_MODELS_DIR + '/Experiment2/IDW/16nodes/tune2/completed_tuner2.pth.tar')\n",
    "# checkpoint = load_model(TRAINED_MODELS_DIR + '/Experiment2/harmonie/32nodes/tune2/completed_tuner2.pth.tar')\n",
    "\n",
    "# Meteo only\n",
    "# checkpoint = load_model(TRAINED_MODELS_DIR + '/Experiment2/IDW/16nodes/meteonet/meteonet.pth.tar')\n",
    "\n",
    "model_f1 = checkpoint['best_model_f1']\n",
    "model_avg = checkpoint['best_model_avg']\n",
    "\n",
    "# Get stats\n",
    "best_epoch_f1, best_epoch_avg = checkpoint['best_epoch_f1'], checkpoint['best_epoch_avg']\n",
    "best_f1_value, best_avg_value = checkpoint['best_f1'], checkpoint['best_avg_acc']\n",
    "print('Best overall accuracy: {:.2f}%.'.format(checkpoint['best_accuracy']))\n",
    "print('Best average accuracy: {:.2f}%. At epoch {}'.format(best_avg_value, best_epoch_avg))\n",
    "print('Best f1-macro: {:.3f}. At epoch {}'.format(best_f1_value, best_epoch_f1))\n",
    "\n",
    "try:\n",
    "    print('Confusion Matrix best f1-macro validation:')\n",
    "    show_cm(checkpoint['f1_val_targets'], checkpoint['f1_val_preds'])\n",
    "\n",
    "    print('Confusion Matrix best avg accuracy validation:')\n",
    "    show_cm(checkpoint['avg_val_targets'], checkpoint['avg_val_preds'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "train_loss = checkpoint['train_loss']\n",
    "validation_loss = checkpoint['validation_loss']\n",
    "plot_loss_curves(train_loss, validation_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix test set average accuracy:\n",
      "Test stats\n",
      "Overall accuracy: 92.66%\n",
      "Average accuracy: 92.66%\n",
      "f1-macro:0.927\n",
      "f1-micro: 0.927\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fmt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-cd465dbbd57b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# test_model(model_f1, test_dataloader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion matrix test set average accuracy:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'merged'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-143-cd465dbbd57b>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, dataloader, nettype)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                             f1_macro, f1_micro))\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mshow_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# print('Confusion matrix test set f1 macro:')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-9603bdd670bc>\u001b[0m in \u001b[0;36mshow_cm\u001b[0;34m(targets, predictions)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Plot non-normalized confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-139-9603bdd670bc>\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(cm, title, cmap)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         plt.text(j, i, format(cm[i, j], fmt),\n\u001b[0m\u001b[1;32m     22\u001b[0m                  \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"center\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                  color=\"white\" if cm[i, j] > thresh else \"black\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fmt' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117226a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_model(model, dataloader, nettype):\n",
    "    \"\"\"\n",
    "    Tests a specified model on all the manually labeled highway camera\n",
    "    images. \n",
    "    \n",
    "    :param model: Trained model to evaluate\n",
    "    :param test_features: All test features as tensor\n",
    "    :param test_targets: All test labels as tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    test_images, test_targets, idx, test_filepaths, meteo = next(iter(dataloader))\n",
    "    \n",
    "    # Loss criterion\n",
    "    criterion = nn.CrossEntropyLoss(reduce=False)\n",
    "    \n",
    "    # Wrap tensors\n",
    "    features = Variable(test_images)\n",
    "    targets = Variable(test_targets)\n",
    "    meteo = Variable(meteo.type(torch.FloatTensor))\n",
    "    total = len(targets)\n",
    "    \n",
    "    if nettype == 'meteo':\n",
    "        outputs = model(meteo)\n",
    "    elif nettype == 'images':\n",
    "        outputs = model(features)\n",
    "    elif nettype == 'merged':\n",
    "        outputs = model(features, meteo)\n",
    "    \n",
    "    # Loss and optimization\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Get test predictions and number of correct predictions\n",
    "    _, predictions = torch.max(outputs.data, 1) \n",
    "    correct = torch.sum(predictions == targets.data)  \n",
    "    corrects = predictions == targets.data\n",
    "    \n",
    "#     plot_most_uncertain(outputs, corrects, predictions, loss, 0, k=20)\n",
    "    \n",
    "#     for i, cor in enumerate(corrects):\n",
    "#         if predictions[i] == 1 and cor == 0:\n",
    "#             print(test_filepaths[i])\n",
    "#             print(test_targets[i])\n",
    "#             img = test_features[i]\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "             \n",
    "    image_indices = list(range(0, total))\n",
    "#     plot_images(loss, image_indices, test_filepaths, targets, predictions, phase='test', amount=50)\n",
    "    \n",
    "    test_accuracy = correct / total * 100\n",
    "    avg_accuracy = get_average_accuracy(targets.data.numpy(), predictions.numpy())\n",
    "\n",
    "    f1_macro = f1_score(targets.data.numpy(), predictions.numpy(), average='macro')\n",
    "    f1_micro = f1_score(targets.data.numpy(), predictions.numpy(), average='micro')\n",
    "    \n",
    "    print('Test stats\\nOverall accuracy: {:.2f}%\\n'\n",
    "          'Average accuracy: {:.2f}%\\nf1-macro:' \n",
    "          '{:.3f}\\nf1-micro: {:.3f}'.format(test_accuracy, avg_accuracy,\n",
    "                                            f1_macro, f1_micro))\n",
    "    \n",
    "    show_cm(list(targets.data), list(predictions))\n",
    "\n",
    "# print('Confusion matrix test set f1 macro:')\n",
    "# test_model(model_f1, test_dataloader)\n",
    "print('Confusion matrix test set average accuracy:')\n",
    "test_model(model_avg, test_dataloader, 'merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(loss, image_index, filepaths, targets, predictions, phase, amount=15):\n",
    "    \"\"\"\n",
    "    Use to plot images that the model is most certain about and which it was most uncertain about.\n",
    "    \n",
    "    :param loss: Tensor that has size of batch containing loss\n",
    "    :param filepaths: List with filepaths that point to where batch images are located\n",
    "    :param amount: Amount of images to show. Default: 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def loop_plot(indices, targets, predictions, filepaths, losses, phase, amount):    \n",
    "        fig=plt.figure(figsize=(20, amount))\n",
    "        columns = 5\n",
    "        rows = amount / 5\n",
    "        \n",
    "        # Determine phase and get image np array\n",
    "        if phase == 'train':\n",
    "            image_array = X_train\n",
    "        elif phase == 'validation':\n",
    "            image_array = X_validation\n",
    "        else:\n",
    "            image_array = test_features\n",
    "        print(filepaths)\n",
    "        # Loop over the data and plot 'amount' of images\n",
    "        for i, (index, target, prediction, loss) in enumerate(zip(indices, targets, predictions, losses)):\n",
    "            img = image_array[index]\n",
    "            fig.add_subplot(rows, columns, i + 1)\n",
    "            plt.title('target: {}, prediction: {} loss: {:.2f}'.format(target, prediction, loss))\n",
    "            plt.imshow(img)\n",
    "      \n",
    "        plt.show()\n",
    "    \n",
    "    def get_k_and_plot(loss, amount, targets, image_index, filepaths, predictions, phase, largest=True):\n",
    "        # Get all relevant data\n",
    "        values, indices = torch.topk(loss, amount, largest=largest)\n",
    "        targets = [targets[i].data[0] for i in list(indices.data.cpu().numpy().reshape((1, -1))[0])]\n",
    "        images_idx = [image_index[i] for i in list(indices.data.cpu().numpy().reshape((1, -1))[0])]\n",
    "        filepaths = [filepaths[i] for i in list(indices.data.cpu().numpy().reshape((1, -1))[0])]\n",
    "        predictions = [predictions[i] for i in list(indices.data.cpu().numpy().reshape((1, -1))[0])]\n",
    "        loss = [loss.data[i] for i in list(indices.data.cpu().numpy().reshape((1, -1))[0])]\n",
    "\n",
    "        # Show images (uncertain/certain)\n",
    "        loop_plot(images_idx, targets, predictions, filepaths, loss, phase, amount)\n",
    "\n",
    "    print('Top {} most uncertain images'.format(amount))\n",
    "    get_k_and_plot(loss, amount, targets, image_index, filepaths, predictions, phase, largest=True)\n",
    "\n",
    "    \n",
    "    print('Top {} most certain images'.format(amount))\n",
    "    get_k_and_plot(loss, amount, targets, image_index, filepaths, predictions, phase, largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no significant performance in accuracy between model 1 (p1 = 0.9266) and model 2 (0.9104).\n",
      "z = 1.188 with p-value: 0.117\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "def perform_ztest(p1, p2, n, bonferonni):\n",
    "    '''\n",
    "    Performs pairwise Z-test on two accuracies for the test sets. \n",
    "    \n",
    "    :param p1: Accuracy of model 1\n",
    "    :param p2: Accuracy of model 2\n",
    "    :param n: Number of samples for model 1 and model 2 (same in our case)\n",
    "    :param bonferonni: Positive integer determining number of pairwise z-tests perormed\n",
    "    '''\n",
    "    # Determine significance level\n",
    "    alpha = 0.05 / bonferonni\n",
    "    \n",
    "    # Statistics\n",
    "    Z = (p1 - p2) / np.sqrt(((p1 * (1 - p1)) / n ) + ((p2 * (1 - p2)) / n))\n",
    "    p = scipy.stats.norm.sf(abs(Z))\n",
    "\n",
    "    if p > alpha:\n",
    "        print('There is no significant performance in accuracy between model 1 (p1 = {}) and model 2 ({}).\\n'\n",
    "        'z = {:.3f} with p-value: {:.3f}'.format(p1, p2, Z, p))\n",
    "    else:\n",
    "         print('There is a significant difference in accuracy between model 1 (p2 = {}) and model 2 ({}).\\n'\n",
    "       'z = {:2f} with p-value: {:.3f}'.format(p1, p2, Z, p))\n",
    "    \n",
    "    \n",
    "perform_ztest(0.9266, 0.9104, len(test_targets), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science_36",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
