{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timmolleman/anaconda3/envs/data_science_36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsample\n",
    "import psycopg2\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import copy\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchsample import transforms as ts_transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.load('../data/processed/test_images.npy')\n",
    "test_targets = np.load('../data/processed/test_targets.npy')\n",
    "test_filepaths = np.load('../data/processed/test_filepaths.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load('../data/processed/chec')\n",
    "y_train =\n",
    "y_paths ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'targets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d5aa1d61b2e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclass_light\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'targets' is not defined"
     ]
    }
   ],
   "source": [
    "class_dense = list(np.where(targets==2))\n",
    "class_light = list(np.where(targets==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Proportions (for Weighted Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-27f824c94dba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the class proportions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mproportion_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mproportion_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_validation' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the class proportions\n",
    "class_counts = np.bincount(y_validation.astype(int))\n",
    "total = len(y_validation)\n",
    "proportion_0 = class_counts[0] / total\n",
    "proportion_1 = class_counts[1] / total\n",
    "proportion_2 = class_counts[2] / total\n",
    "\n",
    "print('Class percentages:\\nNo fog: {:.2f}%\\nFog: {:.2f}%\\nDense fog: {:.2f}%'.format(proportion_0 * 100,\n",
    "                                                                              proportion_1 * 100, proportion_2 * 100))\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List containing class probabilities\n",
    "probabilities = [proportion_0, proportion_1, proportion_2]\n",
    "reciprocal_weights = []\n",
    "\n",
    "# Put weight at every index\n",
    "for i in range(len(X_train)):\n",
    "    reciprocal_weights.append(probabilities[train_targets[i]])\n",
    "\n",
    "# Inverse of probabilities as weights\n",
    "weights = (1 / torch.Tensor(reciprocal_weights))\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights.double(), len(X_train))\n",
    "\n",
    "# Inverse weights for all the datapoints\n",
    "inverse_weights_class = 1 / torch.Tensor(probabilities)\n",
    "\n",
    "# Inverse weights per class\n",
    "inverse_weights = 1 / torch.Tensor(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomCrop(80),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'validation': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.CenterCrop(80),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class KNMIDataset(Dataset):\n",
    "    def __init__(self, images, targets, filepaths, transforms=None):\n",
    "    \n",
    "        self.transforms = transforms\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.filepaths = filepaths\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transforms != None:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        target = self.targets[index]\n",
    "        filepath = self.filepaths[index]\n",
    "        \n",
    "        return (image, target, index, filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 164\n",
    "\n",
    "# Datasets\n",
    "train_dataset = KNMIDataset(X_train, train_targets, paths_train, transforms=data_transforms['train'])\n",
    "validation_dataset = KNMIDataset(X_validation, validation_targets, paths_validation, transforms=data_transforms['validation'])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = DataLoader(dataset=validation_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "loaders = {'train': train_loader, 'validation': validation_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Batch Iteration Size of Trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iteration for one train/testloader batch\n",
    "img, labels, idx, paths = next(iter(validation_loader))\n",
    "inputs, labels = Variable(img), Variable(labels)\n",
    "print('Loader image tensor shape: {}\\nLoader targets tensor shape: {}'.format(inputs.size(), labels.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Confusion matrix helper\n",
    "def show_cm(targets, predictions):\n",
    "    cm = confusion_matrix(y_target=targets, \n",
    "                      y_predicted=predictions, \n",
    "                      binary=False)\n",
    "\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Curve Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_curves(training_loss, validation_loss):\n",
    "    \"\"\"\n",
    "    Plots loss curves after model training.\n",
    "    \n",
    "    :param training_loss: List with training loss for every epoch.\n",
    "    :param validation_loss: List with validation loss for every epoch.\n",
    "    \"\"\"\n",
    "    train_plot, = plt.plot(training_loss, label='Training')\n",
    "    val_plot, = plt.plot(validation_loss, label='Validation')\n",
    "    plt.title('Loss curves (training/validation)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(handles=[train_plot, val_plot])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Certain/Uncertain Images Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(loss, image_index, filepaths, targets, predictions, phase, amount=5):\n",
    "    \"\"\"\n",
    "    Use to plot images that the model is most certain about and which it was most uncertain about.\n",
    "    \n",
    "    :param loss: Tensor that has size of batch containing loss\n",
    "    :param filepaths: List with filepaths that point to where batch images are located\n",
    "    :param amount: Amount of images to show. Default: 1\n",
    "    \"\"\"\n",
    "    \n",
    "    def loop_plot(indices, targets, predictions, filepaths, losses, phase):    \n",
    "        fig=plt.figure(figsize=(20, 5))\n",
    "        columns = 5\n",
    "        rows = 1\n",
    "        \n",
    "        # Determine phase and get image np array\n",
    "        if phase == 'train':\n",
    "            image_array = X_train\n",
    "        elif phase == 'validation':\n",
    "            image_array = X_validation\n",
    "        else:\n",
    "            image_array = test_images\n",
    "        print(filepaths)\n",
    "        # Loop over the data and plot 'amount' of images\n",
    "        for i, (index, target, prediction, loss) in enumerate(zip(indices, targets, predictions, losses)):\n",
    "            img = image_array[index]\n",
    "            fig.add_subplot(rows, columns, i + 1)\n",
    "            plt.title('target: {}, prediction: {} loss: {:.2f}'.format(target, prediction, loss))\n",
    "            plt.imshow(img)\n",
    "      \n",
    "        plt.show()\n",
    "    \n",
    "    def get_k_and_plot(loss, amount, targets, image_index, filepaths, predictions, phase, largest=True):\n",
    "        # Get all relevant data\n",
    "        values, indices = torch.topk(loss, amount, largest=largest)\n",
    "        targets = [targets[i].data[0] for i in list(indices.data.numpy().reshape((1, -1))[0])]\n",
    "        images_idx = [image_index[i] for i in list(indices.data.numpy().reshape((1, -1))[0])]\n",
    "        filepaths = [filepaths[i] for i in list(indices.data.numpy().reshape((1, -1))[0])]\n",
    "        predictions = [predictions[i] for i in list(indices.data.numpy().reshape((1, -1))[0])]\n",
    "        loss = [loss.data[i] for i in list(indices.data.numpy().reshape((1, -1))[0])]\n",
    "\n",
    "        # Show images (uncertain/certain)\n",
    "        loop_plot(images_idx, targets, predictions, filepaths, loss, phase)\n",
    "\n",
    "    print('Top {} most uncertain images'.format(amount))\n",
    "    get_k_and_plot(loss, amount, targets, image_index, filepaths, predictions, phase, largest=True)\n",
    "\n",
    "    print('Top {} most certain images'.format(amount))\n",
    "    get_k_and_plot(loss, amount, targets, image_index, filepaths, predictions, phase, largest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs):\n",
    "    \"\"\"\n",
    "    Does the actual training of the models.\n",
    "    \n",
    "    :param model: Model object specified in 'run_model'.\n",
    "    :param criterion: Optimization criterion/loss.\n",
    "    :param optimizer: Type of optimizer.\n",
    "    :param num_epochs: Number of epochs to train.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # For storing loss for curve, best model and best accuracy\n",
    "    train_loss, validation_loss = [],[]\n",
    "    best_model = model\n",
    "    best_accuracy = 0.0\n",
    "    best_f1macro = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Running loss and correct predictions\n",
    "        running_loss_train = 0.0\n",
    "        running_correct_train = 0.0\n",
    "        running_loss_val = 0.0\n",
    "        running_correct_val = 0.0\n",
    "        epoch_validation_targets = []\n",
    "        epoch_validation_predictions = []\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "\n",
    "            # Change model mode according to phase \n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            # Iterate over batches in loader\n",
    "            for i, (image_tensor, label_tensor, image_index, filepaths) in enumerate(loaders[phase]):\n",
    "\n",
    "                features = Variable(image_tensor)\n",
    "                targets = Variable(label_tensor.view(-1))\n",
    "\n",
    "                # Forward + Backward + Optimize\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(features)\n",
    "\n",
    "                # Get prediction index and no. correct predictions\n",
    "                _, predictions = torch.max(outputs.data, 1) \n",
    "                \n",
    "                # Kijk hier uit dat die testloader precies aantal batches in de validation data haalt \n",
    "                correct = torch.sum(predictions == targets.data) \n",
    "\n",
    "                # Loss and optimization\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Average the loss\n",
    "                total_loss = torch.mean(loss)\n",
    "                \n",
    "                # Only do backpropagation if in the training phase\n",
    "                if phase == 'train':\n",
    "                    total_loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Running loss and number of correct predictions\n",
    "                if phase == 'train':\n",
    "                    running_loss_train += total_loss.data[0]\n",
    "                    running_correct_train += correct\n",
    "                else:\n",
    "                    running_loss_val += total_loss.data[0]\n",
    "                    running_correct_val += correct\n",
    "                    epoch_validation_targets.extend(list(targets.data))\n",
    "                    epoch_validation_predictions.extend(list(predictions))\n",
    "                    \n",
    "                    # Plot images in validation phase\n",
    "                    plot_images(loss, image_index, filepaths, targets, predictions, phase)\n",
    "\n",
    "                # If model is in training phase, show loss every N iterations\n",
    "                if (i+1) % 5 == 0:\n",
    "                    if phase == 'train':\n",
    "                        print ('Epoch {}/{}, Iteration {}/{} Train Running Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, \n",
    "                                                                                    len(X_train)//BATCH_SIZE, \n",
    "                                                                                    running_loss_train / i))\n",
    "#                         plot_images(loss, image_index, filepaths, targets, predictions, phase)\n",
    "                    \n",
    "\n",
    "        # Epoch losses and epoch train accuracies\n",
    "        epoch_train_loss = running_loss_train / (len(X_train)//BATCH_SIZE)\n",
    "        epoch_train_accuracy = (running_correct_train / (len(X_train)//BATCH_SIZE)) / BATCH_SIZE * 100\n",
    "        epoch_val_loss = running_loss_val / len(X_validation//BATCH_SIZE)\n",
    "        epoch_val_accuracy= running_correct_val / len(X_validation) * 100\n",
    "        \n",
    "        # F1-score\n",
    "        f1_macro = f1_score(epoch_validation_targets, epoch_validation_predictions, average='macro')\n",
    "        f1_micro = f1_score(epoch_validation_targets, epoch_validation_predictions, average='micro')\n",
    "        precision = precision_score(epoch_validation_targets, epoch_validation_predictions, average='macro')\n",
    "        recall = recall_score(epoch_validation_targets, epoch_validation_predictions, average='macro')\n",
    "\n",
    "        # Print the average epoch loss and the average prediction accuracy\n",
    "        print('\\nEpoch {}/{}, Train Loss: {:.4f}, Train Accuracy: {:.4f}%\\n'\n",
    "              'Validation Loss: {:.4f}, Validation Accuracy: {:.4f}%, f1-score {:.4f}\\n'.format(epoch + 1, \n",
    "                                                                    num_epochs, epoch_train_loss, epoch_train_accuracy,\n",
    "                                                                     epoch_val_loss, epoch_val_accuracy, f1))\n",
    "        \n",
    "        # Safe best model and best accuracy \n",
    "        if phase == 'validation':\n",
    "            if epoch_val_accuracy > best_accuracy:\n",
    "                best_accuracy = epoch_val_accuracy\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "        # Show the confusion matrix for validation targets/predictions\n",
    "        show_cm(epoch_validation_targets, epoch_validation_predictions)\n",
    "        \n",
    "        # Append losses\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        validation_loss.append(epoch_val_loss)\n",
    "        \n",
    "    # Elapsed time and best accuracy\n",
    "    elapsed_time = time.time() - start\n",
    "    print('Training was completed in {:.0f}m {:.0f}s\\n'.format(elapsed_time//60, elapsed_time%60))\n",
    "    print('Best validation accuracy: {:4f}%'.format(best_accuracy))\n",
    "    \n",
    "    # Plot loss curves\n",
    "    plot_loss_curves(train_loss, validation_loss)\n",
    "    \n",
    "    # Return the best model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(model, epochs, learning_rate, train_from_layer=False, last_layer_trained=False, not_self_defined=True):\n",
    "    '''\n",
    "    Configures model object and then calls 'train_model' for model training. \n",
    "    \n",
    "    :param train_from_layer: Specify number of layers before fully-connected to also be finetuned. Default is False,\n",
    "    which will just train the fc layers. Give a number to specify number of layers before that. \n",
    "    :param model: This is a (pre-trained) model that will be further finetuned.\n",
    "    :param epochs: Number of epochs to train.\n",
    "    :param learning_rate: Learning rate for the parameters.\n",
    "    :param not_self_defined: True if model architecture is used from torchvision. False if model is self-defined. \n",
    "    '''\n",
    "    \n",
    "    if not_self_defined:\n",
    "      \n",
    "        # Set all parameter training to false\n",
    "        for parameter in model.parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "        # Select number of pre-trained layers to finetune\n",
    "        if train_from_layer != False:\n",
    "            ct = 0\n",
    "            print(ct)\n",
    "\n",
    "            for name, child in model.named_children():\n",
    "                ct += 1\n",
    "\n",
    "                if ct > train_from_layer:\n",
    "                    for name2, params in child.named_parameters():\n",
    "                        params.requires_grad = True\n",
    "\n",
    "          # Get parameters that need finetuning\n",
    "            optim_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "    # Adjust final layer to number of classes if last layer has not been trained yet\n",
    "    if last_layer_trained == False:\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, TARGET_SIZE)\n",
    "        optim_params = model.fc.parameters()\n",
    "    \n",
    "    # Train all parameters if model is not predefined from torchvision\n",
    "    else: \n",
    "        optim_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        inverse_weights.cuda()\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # Optimizers and loss criterions\n",
    "    criterion = nn.CrossEntropyLoss(reduce=False, weight=inverse_weights)\n",
    "    optimizer = optim.Adam(optim_params, lr=learning_rate)        \n",
    "    \n",
    "    # Train and save\n",
    "    trained_model = train_model(model, criterion, optimizer, epochs)\n",
    "    \n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_classifier = 2e-4\n",
    "lr_tuner = 1e-4\n",
    "\n",
    "# Train last FC layer of resnet 18\n",
    "resnet_18 = models.resnet18(pretrained=True)\n",
    "resnet_18.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "resnet_18_trained = run_model(resnet_18, 10, lr_classifier, False)\n",
    "\n",
    "# Tune also the last convolutional layer\n",
    "# resnet_18_tuned = run_model(resnet_18_trained, 15, lr_tuner, train_from_layer=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simple_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,              # input height\n",
    "                out_channels=16,            # n_filters\n",
    "                kernel_size=3,              # filter size\n",
    "                stride=1,                   # filter movement/step\n",
    "                padding=2,                  # if want same width and length of this image after con2d, padding=(kernel_size-1)/2 if stride=1\n",
    "            ),                              # output shape (16, 28, 28)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # choose max value in 2x2 area, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 3, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(32, 32, 3, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation\n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.out = nn.Linear(3872, 3)   # fully connected layer, output 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = self.dropout(x) \n",
    "        output = self.out(x)\n",
    "        return output   # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model = simple_CNN()\n",
    "run_model(simple_model, 10, 0.001, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Model Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(filepath):\n",
    "    '''\n",
    "    Loads a trained model.\n",
    "    \n",
    "    :param filepath: Path to the trained model.\n",
    "    '''\n",
    "    loaded_model = torch.load(filepath, map_location=lambda storage, loc: storage)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINED_MODELS_DIR = '/Volumes/TIMPP/TrainedModels'\n",
    "\n",
    "loaded_checkpoint = load_model(TRAINED_MODELS_DIR + '/highway-images/resnet-18/Resnet18-FirstBest/classifier/resnet18_classifier.pth.tar')\n",
    "current_model_tuned = load_model(TRAINED_MODELS_DIR + '/highway-images/resnet-18/Resnet18-FirstBest/tuner/resnet18_tuner.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current_model_trained = load_model(TRAINED_MODELS_DIR + '/highway-images/resnet18/classifier')\n",
    "loaded_checkpoint = load_model(TRAINED_MODELS_DIR + '/knmi-images/resnet18/tuner/KNMItuner.pth.tar')\n",
    "current_model_train = loaded_checkpoint['best_model']\n",
    "loaded_checkpoint['best_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_loss_lists(full_train):\n",
    "    '''\n",
    "    :param full_train: List of model trained models in different phases.\n",
    "    '''\n",
    "    train_loss = []\n",
    "    validation_loss = []\n",
    "    \n",
    "    for train_phase in full_train:\n",
    "        best_epoch = train_phase['best_epoch']\n",
    "        phase_train_loss = train_phase['train_loss'][:best_epoch] \n",
    "        phase_val_loss = train_phase['validation_loss'][:best_epoch]\n",
    "        \n",
    "        for i, j in zip(phase_train_loss, phase_val_loss):\n",
    "            train_loss.append(i)\n",
    "            validation_loss.append(j)\n",
    "    \n",
    "    return train_loss, validation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset and Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = KNMIDataset(test_features, test_targets, test_filepaths, transforms=data_transforms['validation'])\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_checkpoint = load_model('../../../../Downloads/checkpoint21.pth.tar')\n",
    "current_model_train = loaded_checkpoint['state_dict']\n",
    "best_epoch = loaded_checkpoint['best_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12472dba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curves(loaded_checkpoint['train_loss'], loaded_checkpoint['validation_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 68.01%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13cb70d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Tests a specified model on all the manually labeled highway camera\n",
    "    images. \n",
    "    \n",
    "    :param model: Trained model to evaluate\n",
    "    :param test_features: All test features as tensor\n",
    "    :param test_targets: All test labels as tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    test_images, test_targets, idx, test_filepaths = next(iter(dataloader))\n",
    "    \n",
    "    # Loss criterion\n",
    "    criterion = nn.CrossEntropyLoss(reduce=False)\n",
    "    \n",
    "    # Wrap tensors\n",
    "    features = Variable(test_images)\n",
    "    targets = Variable(test_targets)\n",
    "    total = len(targets)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Feed test features into model\n",
    "    outputs = model(features)\n",
    "    \n",
    "    # Loss and optimization\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Get test predictions and number of correct predictions\n",
    "    _, predictions = torch.max(outputs.data, 1) \n",
    "    correct = torch.sum(predictions == targets.data)\n",
    "    \n",
    "    corrects = predictions == targets.data\n",
    "    \n",
    "#     for i, cor in enumerate(corrects):\n",
    "#         if predictions[i] == 2 and cor == 0 and test_targets[i] == 1:\n",
    "#             print(test_filepaths[i])\n",
    "#             print(test_targets[i])\n",
    "#             img = test_features[i]\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "            \n",
    "    \n",
    "    image_indices = list(range(0, total))\n",
    "#     plot_images(loss, image_indices, test_filepaths, targets, predictions, phase='test')\n",
    "    \n",
    "    test_accuracy = correct / total * 100  \n",
    "    print('Test accuracy: {:.2f}%'.format(test_accuracy))\n",
    "    show_cm(list(targets.data), list(predictions))\n",
    "    \n",
    "test_model(current_model_train, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science_36",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
